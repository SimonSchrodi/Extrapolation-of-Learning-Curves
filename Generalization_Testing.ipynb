{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "colab": {
      "name": "Task B.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kvfy0a0V7oJT",
        "colab_type": "text"
      },
      "source": [
        "# Task B: Meta-Learning Perfomance Prediction\n",
        "\n",
        "In this task, you will use information on training parameters and metadata on multiple OpenML dataset to train a performance predictor that performs well even for unseen datasets. You are provided with config parameters and metafeatures for six datasets. The datasets are split into training datasets and test datasets and you should only train on the training datasets.\n",
        "\n",
        "For questions, you can contact zimmerl@informatik.uni-freiburg.\n",
        "\n",
        "__Note: Please use the dataloading and splits you are provided with in this notebook.__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WpFXeJF7oJW",
        "colab_type": "text"
      },
      "source": [
        "## Specifications:\n",
        "\n",
        "* Data: six_datasets_lw.json\n",
        "* Number of datasets: 6\n",
        "* Training datasets: higgs, vehicle, adult, volkert\n",
        "* Test datasets: Fashion-MNIST, jasmine\n",
        "* Number of configurations: 2000\n",
        "* Available data: architecture parameters and hyperparameters, metafeatures \n",
        "* Target: final validation accuracy\n",
        "* Evaluation metric: MSE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kB_QgoI97oJb",
        "colab_type": "text"
      },
      "source": [
        "## Importing and splitting data\n",
        "\n",
        "Note: There are 51 steps logged, 50 epochs plus the 0th epoch, prior to any weight updates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODNXUQUq7-57",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "57baef8c-9e55-47e4-8ff3-36aa77016e31"
      },
      "source": [
        "!pip install wget\n",
        "!pip install zipfile36"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=870a1af212056deac29f3ec16b9d0dcbb2e30bab8cfe231cd6172cee38b6fe91\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Collecting zipfile36\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/8a/3b7da0b0bd87d1ef05b74207827c72d348b56a0d6d83242582be18a81e02/zipfile36-0.1.3-py3-none-any.whl\n",
            "Installing collected packages: zipfile36\n",
            "Successfully installed zipfile36-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7L03emy7_rr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f9aac79d-1e9e-46cb-d95a-a70cba6d064f"
      },
      "source": [
        "import wget\n",
        "import zipfile\n",
        "dir_path = 'content/'\n",
        "filename=wget.download('https://ndownloader.figshare.com/articles/11604705/versions/1')\n",
        "with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"\")\n",
        "with zipfile.ZipFile(dir_path+\"six_datasets_lw.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"\")\n",
        "!rm six_datasets_lw.zip\n",
        "filename=wget.download('https://ndownloader.figshare.com/files/21188673')\n",
        "wget.download('https://raw.githubusercontent.com/automl/LCBench/master/api.py')\n",
        "wget.download('https://raw.githubusercontent.com/infomon/Extrapolation-of-Learning-Curves/master/utils.py')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'utils (1).py'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLu8YSzL7oJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "%cd ..\n",
        "import numpy as np\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from content.api import Benchmark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nemsMBHh7oJj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "db2575fe-4681-4ea7-c488-4376f040b2d0"
      },
      "source": [
        "bench_dir = \"six_datasets_lw.json\"\n",
        "bench = Benchmark(bench_dir, cache=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Loading data...\n",
            "==> No cached data found or cache set to False.\n",
            "==> Reading json data...\n",
            "==> Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuYb6mXO7oJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"metafeatures.json\", \"r\") as f:\n",
        "    metafeatures = json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA33xm7b7oJs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "53fd3909-db91-490e-ca66-52e4a8c594b0"
      },
      "source": [
        "# Dataset split\n",
        "dataset_names = bench.get_dataset_names()\n",
        "print(dataset_names)\n",
        "\n",
        "test_datasets = ['adult', 'higgs', 'vehicle', 'volkert','jasmine']\n",
        "test_datasets = ['higgs']"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Fashion-MNIST', 'adult', 'higgs', 'jasmine', 'vehicle', 'volkert']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSsPorOj7oJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare data\n",
        "def read_data(datasets):\n",
        "    n_configs = bench.get_number_of_configs(datasets[0])\n",
        "    data = [bench.query(dataset_name=d, tag=\"Train/val_accuracy\", config_id=ind) for d in datasets for ind in range(n_configs)]\n",
        "    configs = [bench.query(dataset_name=d, tag=\"config\", config_id=ind) for d in datasets for ind in range(n_configs)]\n",
        "    dataset_names = [d for d in datasets for ind in range(n_configs)]\n",
        "    \n",
        "    data = np.array(data)\n",
        "    number_of_samples = data.shape[0]\n",
        "    a = []\n",
        "    for i in range(number_of_samples):\n",
        "      a.append({'Train/val_accuracy':data[i,0:10],'config':configs[i]})\n",
        "\n",
        "    #y = np.array([curve[-1] for curve in data])\n",
        "    y = np.array([curve for curve in data])\n",
        "    #return np.array(configs), y, np.array(dataset_names)\n",
        "    return np.array(a), y, np.array(dataset_names)\n",
        "\n",
        "class TrainValSplitter():\n",
        "    \"\"\"Splits 25 % data as a validation split.\"\"\"\n",
        "    \n",
        "    def __init__(self, dataset_names):\n",
        "        self.ind_train, self.ind_val = train_test_split(np.arange(len(X)), test_size=0.25, stratify=dataset_names)\n",
        "        \n",
        "    def split(self, a):\n",
        "        return a[self.ind_train], a[self.ind_val]\n",
        "\n",
        "X_test, y_test, dataset_names_test = read_data(test_datasets)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm0--zfKA8Gl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "of9PazMfAYS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_loader = utils.prep_data(X_test, y_test, batch_size=32,normalization_factor_temporal_data=[100])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzr-XZV07oJ0",
        "colab_type": "text"
      },
      "source": [
        "The data contains the configuration.\n",
        "\n",
        "__Note__: Not all parameters vary across different configurations. The varying parameters are batch_size, max_dropout, max_units, num_layers, learning_rate, momentum, weight_decay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ue6AwjzK7oJ_",
        "colab_type": "text"
      },
      "source": [
        "## Training and scoring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMkohn6oI7NV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "multivariate = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRT12-RkHfOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_batch(batch):\n",
        "  temporal = batch[:nof_multi if multivariate else 1]\n",
        "  temporal = torch.stack([t for t in temporal],dim=0)\n",
        "  configs = batch[-2]\n",
        "  targets = batch[-1]\n",
        "  return temporal, configs, targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMtRiGAwGp6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss=[]\n",
        "    with torch.no_grad():\n",
        "      for batch in test_data_loader:\n",
        "        temporal, configs, targets = preprocess_batch(batch)\n",
        "        output = model([temporal, configs], targets, 0)\n",
        "        output = output.squeeze()\n",
        "        output = torch.t(output)\n",
        "        loss = criterion(output[:,-1], targets[:,-1])\n",
        "        epoch_loss.append(loss.item())\n",
        "        \n",
        "    return np.array(epoch_loss).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqyuzIqaIHhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHNrvvQyHU2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderRNN(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, nof_configs, num_layers, dropout = 0.5, bidirectional=False):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        \n",
        "        self.nof_configs = nof_configs\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "        self.bidirectional = bidirectional\n",
        "        self.num_directions = 2 if bidirectional else 1\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = torch.nn.LSTM(input_size=input_size, \n",
        "                                  hidden_size=hidden_size,\n",
        "                                  num_layers=num_layers,\n",
        "                                  dropout=dropout,\n",
        "                                  bidirectional=bidirectional)\n",
        "\n",
        "        self.relu = torch.nn.functional.relu\n",
        "\n",
        "        self.encode_fc1 = torch.nn.Linear(self.nof_configs,int(self.hidden_size/2))\n",
        "        self.encode_bn1 = torch.nn.BatchNorm1d(int(self.hidden_size/2))\n",
        "        self.encode_fc2 = torch.nn.Linear(int(self.hidden_size/2),self.hidden_size)\n",
        "        self.encode_bn2 = torch.nn.BatchNorm1d(self.hidden_size)\n",
        "\n",
        "    def forward(self, seq, config):\n",
        "        h0 = self.initHidden(config)\n",
        "        c0 = self.initCell(seq.size()[1])\n",
        "        seq = seq.permute(2,1,0)\n",
        "        output, (hidden,cell) = self.lstm(seq, (h0,c0))\n",
        "        return output, hidden, cell\n",
        "\n",
        "    def initHidden(self, config):\n",
        "        x = self.relu(self.encode_bn1(self.encode_fc1(config)))\n",
        "        x = self.relu(self.encode_bn2(self.encode_fc2(x)))\n",
        "        return torch.stack([x for _ in range(self.num_layers*self.num_directions)])\n",
        "\n",
        "    def initCell(self, batch_size):\n",
        "        return torch.zeros(self.num_layers*self.num_directions, batch_size, self.hidden_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Nk5ZFSmHXO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderRNN(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers, dropout = 0.5):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        \n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = torch.nn.LSTM(input_size=input_size, \n",
        "                                  hidden_size=hidden_size,\n",
        "                                  num_layers=num_layers,\n",
        "                                  dropout=dropout,\n",
        "                                  bidirectional=False)\n",
        "        \n",
        "        self.fc_out = torch.nn.Linear(hidden_size, output_size)\n",
        "        self.relu = torch.nn.functional.relu\n",
        "\n",
        "    def forward(self, seq, h0, c0):\n",
        "        seq = seq.unsqueeze(0)\n",
        "        seq = seq.unsqueeze(-1)\n",
        "        output, (hidden,cell) = self.lstm(seq, (h0,c0))\n",
        "        output = self.fc_out(output)\n",
        "        return output.squeeze(), hidden, cell\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS7RPxZhHZpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2Seq(torch.nn.Module):\n",
        "  def __init__(self, encoder, decoder):\n",
        "    super(Seq2Seq, self).__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "    assert encoder.hidden_size == decoder.hidden_size\n",
        "    #assert encoder.num_layers == decoder.num_layers\n",
        "\n",
        "  def forward(self, source, target, teacher_forcing_ratio = 0.5):\n",
        "    batch_size = target.size()[0]\n",
        "    target_len = target.size()[1]\n",
        "\n",
        "    outputs = torch.zeros(target_len, batch_size, 1)\n",
        "\n",
        "    seq , config = source\n",
        "    output, hidden, cell = self.encoder(seq, config)\n",
        "\n",
        "    decoder_input = target[:,0]\n",
        "    for t in range(1, target_len):\n",
        "      output, hidden, cell = self.decoder(decoder_input, hidden, cell)\n",
        "      outputs[t] = output.unsqueeze(-1)\n",
        "      use_teacher_forcing = np.random.random() < teacher_forcing_ratio\n",
        "      decoder_input = target[:,t] if use_teacher_forcing else output\n",
        "    return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3lleZHiGvrg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 500\n",
        "\n",
        "input_size = 1\n",
        "decoder_input_size = 1\n",
        "output_size = 1\n",
        "config_size = 7\n",
        "hidden_size=25\n",
        "encoder_dropout=0.5\n",
        "decoder_dropout=0.5\n",
        "num_layers=2\n",
        "bidirectional = True\n",
        "encoder = EncoderRNN(input_size, hidden_size=hidden_size, nof_configs=config_size, num_layers=num_layers,\n",
        "                      dropout=encoder_dropout,bidirectional=bidirectional)\n",
        "decoder = DecoderRNN(decoder_input_size, hidden_size=hidden_size, output_size=output_size, \n",
        "                      num_layers=2*num_layers if bidirectional else num_layers,dropout=decoder_dropout)\n",
        "model = Seq2Seq(encoder, decoder)\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=10e-3)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6Ag-myMGwMf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_list = []\n",
        "for i in range(5):\n",
        "  model = encoder = EncoderRNN(input_size, hidden_size=hidden_size, nof_configs=config_size, num_layers=num_layers,\n",
        "                      dropout=encoder_dropout,bidirectional=bidirectional)\n",
        "  decoder = DecoderRNN(decoder_input_size, hidden_size=hidden_size, output_size=output_size, \n",
        "                      num_layers=2*num_layers if bidirectional else num_layers,dropout=decoder_dropout)\n",
        "  model = Seq2Seq(encoder, decoder)\n",
        "\n",
        "  model.load_state_dict(torch.load(\"content/model_cond_lstm\"+str(i)+\".pt\"))\n",
        "  model_list.append(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU8sXiIdGy0w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a9fba28b-a030-4110-90f9-2ff9d0bdf705"
      },
      "source": [
        "test_losses = []\n",
        "for i in range(5):\n",
        "  test_losses.append(test(model_list[i],criterion))\n",
        "print(np.array(test_losses).mean())"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "210.86206994435142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxiQ_VG_KZmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def RMSELoss(yhat,y):\n",
        "    return torch.sqrt(torch.mean((yhat-y)**2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHKXJYBqKbNo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8b908f42-8095-491e-f3ca-ebdf6067ddd7"
      },
      "source": [
        "test_losses = []\n",
        "for i in range(5):\n",
        "  test_losses.append(test(model_list[i],RMSELoss))\n",
        "print(np.array(test_losses).mean())"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14.498968578520273\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}