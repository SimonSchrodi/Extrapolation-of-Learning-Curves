{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9-final"
    },
    "colab": {
      "name": "Pre_Conditional_Univariate_LSTM.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oJd_VxDKN8pn"
      },
      "source": [
        "# Task A: Creating a Performance Predictor\n",
        "\n",
        "In this task, you will use training data from 2000 configurations on a single OpenML dataset to train a performance predictor. The data will be splitted into train, test and validation set and we will only use the first 10 epochs of the learning curves for predicitons. You are provided with the full benchmark logs for Fashion-MNIST, that is learning curves, config parameters and gradient statistics, and you can use them freely.\n",
        "\n",
        "For questions, you can contact zimmerl@informatik.uni-freiburg.\n",
        "\n",
        "__Note: Please use the dataloading and splits you are provided with in this notebook.__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cqPBWpd5N8pt"
      },
      "source": [
        "## Specifications:\n",
        "\n",
        "* Data: fashion_mnist.json\n",
        "* Number of datasets: 1\n",
        "* Number of configurations: 2000\n",
        "* Number of epochs seed during prediction: 10\n",
        "* Available data: Learning curves, architecture parameters and hyperparameters, gradient statistics \n",
        "* Target: Final validation accuracy\n",
        "* Evaluation metric: MSE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4eYlSG9BN8py"
      },
      "source": [
        "## Importing and splitting data\n",
        "\n",
        "__Note__: There are 51 steps logged, 50 epochs plus the 0th epoch, prior to any weight updates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Collecting wget\n  Downloading wget-3.2.zip (10 kB)\nBuilding wheels for collected packages: wget\n  Building wheel for wget (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9680 sha256=8ec0d3fe632d8c759e89484c457bd554c15874fc1cf05dfc8b56278a625178b7\n  Stored in directory: /home/sambit/.cache/pip/wheels/90/1d/93/c863ee832230df5cfc25ca497b3e88e0ee3ea9e44adc46ac62\nSuccessfully built wget\nInstalling collected packages: wget\nSuccessfully installed wget-3.2\n\u001b[33mWARNING: You are using pip version 20.0.1; however, version 20.0.2 is available.\nYou should consider upgrading via the '/home/sambit/.pyenv/versions/3.6.9/bin/python3.6 -m pip install --upgrade pip' command.\u001b[0m\nCollecting zipfile36\n  Downloading zipfile36-0.1.3-py3-none-any.whl (20 kB)\nInstalling collected packages: zipfile36\nSuccessfully installed zipfile36-0.1.3\n\u001b[33mWARNING: You are using pip version 20.0.1; however, version 20.0.2 is available.\nYou should consider upgrading via the '/home/sambit/.pyenv/versions/3.6.9/bin/python3.6 -m pip install --upgrade pip' command.\u001b[0m\n"
        }
      ],
      "source": [
        "!pip install wget\n",
        "!pip install zipfile36"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "mkdir: cannot create directory ‘content/models’: No such file or directory\n"
        }
      ],
      "source": [
        "import wget\n",
        "import zipfile\n",
        "dir_path = './content/'\n",
        "filename=wget.download('https://ndownloader.figshare.com/files/21001311')\n",
        "with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"\")\n",
        "!rm fashion_mnist.zip\n",
        "wget.download('https://raw.githubusercontent.com/automl/LCBench/master/api.py')\n",
        "wget.download('https://raw.githubusercontent.com/infomon/Extrapolation-of-Learning-Curves/master/utils.py')\n",
        "!mkdir content/models\n",
        "!mkdir models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'api'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-0f49ca4048eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBenchmark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'api'"
          ]
        }
      ],
      "source": [
        "%%capture\n",
        "%cd ..\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from api import Benchmark\n",
        "import content.utils as utils\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'Benchmark' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-adefd60d1109>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# bench_dir = dir_path+\"fashion_mnist.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbench_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/sambit/PROGRAMMING/DL_PROJECT/TEAM_WORK_FREIBURG/Extrapolation-of-Learning-Curves/DATA/fashion_mnist.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbench\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBenchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbench_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Benchmark' is not defined"
          ]
        }
      ],
      "source": [
        "# bench_dir = dir_path+\"fashion_mnist.json\"\n",
        "bench_dir = '/home/sambit/PROGRAMMING/DL_PROJECT/TEAM_WORK_FREIBURG/Extrapolation-of-Learning-Curves/DATA/fashion_mnist.json'\n",
        "bench = Benchmark(bench_dir, cache=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read data\n",
        "def cut_data(data, cut_position):\n",
        "    targets = []\n",
        "    for dp in data:\n",
        "        targets.append(dp[\"Train/val_accuracy\"][50])\n",
        "        for tag in dp:\n",
        "            if tag.startswith(\"Train/\"):\n",
        "                dp[tag] = dp[tag][0:cut_position]\n",
        "    return data, targets\n",
        "\n",
        "def read_data():\n",
        "    dataset_name = 'Fashion-MNIST'\n",
        "    n_configs = bench.get_number_of_configs(dataset_name)\n",
        "    \n",
        "    # Query API\n",
        "    data = []\n",
        "    for config_id in range(n_configs):\n",
        "        data_point = dict()\n",
        "        data_point[\"config\"] = bench.query(dataset_name=dataset_name, tag=\"config\", config_id=config_id)\n",
        "        for tag in bench.get_queriable_tags(dataset_name=dataset_name, config_id=config_id):\n",
        "            if tag.startswith(\"Train/\"):\n",
        "                data_point[tag] = bench.query(dataset_name=dataset_name, tag=tag, config_id=config_id)    \n",
        "        data.append(data_point)\n",
        "        \n",
        "    # Split: 50% train, 25% validation, 25% test (the data is already shuffled)\n",
        "    indices = np.arange(n_configs)\n",
        "    ind_train = indices[0:int(np.floor(0.5*n_configs))]\n",
        "    ind_val = indices[int(np.floor(0.5*n_configs)):int(np.floor(0.75*n_configs))]\n",
        "    ind_test = indices[int(np.floor(0.75*n_configs)):]\n",
        "\n",
        "    array_data = np.array(data)\n",
        "    train_data = array_data[ind_train]\n",
        "    val_data = array_data[ind_val]\n",
        "    test_data = array_data[ind_test]\n",
        "    \n",
        "    # Cut curves for validation and test\n",
        "    cut_position = 11\n",
        "    val_data, val_targets = cut_data(val_data, cut_position)\n",
        "    test_data, test_targets = cut_data(test_data, cut_position)\n",
        "    train_data, train_targets = cut_data(train_data, 51)   # Cut last value as it is repeated\n",
        "    \n",
        "    return train_data, val_data, test_data, train_targets, val_targets, test_targets\n",
        "    \n",
        "train_data, val_data, test_data, train_targets, val_targets, test_targets = read_data()\n",
        "\n",
        "print(\"Train:\", len(train_data))\n",
        "print(\"Validation:\", len(val_data))\n",
        "print(\"Test:\", len(test_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9PphdZ2aN8qv"
      },
      "source": [
        "The data contains the configuration of the trained model and learning curves as well as global and layer-wise gradient statistics.\n",
        "\n",
        "__Note__: Not all parameters vary across different configurations. The varying parameters are batch_size, max_dropout, max_units, num_layers, learning_rate, momentum, weight_decay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Config\n",
        "print(\"Config example:\", train_data[0][\"config\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data[1][\"config\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Learning curve\n",
        "plt.plot(train_data[10][\"Train/val_accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gradient statistics\n",
        "plt.plot(train_data[10][\"Train/layer_wise_gradient_mean_layer_0\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IaYC_PH4N8rQ"
      },
      "source": [
        "## A simple baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleLearningCurvePredictor():\n",
        "    \"\"\"A learning curve predictor that predicts the last observed epoch of the validation accuracy as final performance\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        pass\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        pass\n",
        "    \n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "        for datapoint in X:\n",
        "            predictions.append(datapoint[\"Train/val_accuracy\"][-1])\n",
        "        return predictions\n",
        "    \n",
        "def score(y_true, y_pred):\n",
        "    return mean_squared_error(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training & tuning\n",
        "predictor = SimpleLearningCurvePredictor()\n",
        "predictor.fit(train_data, train_targets)\n",
        "preds = predictor.predict(val_data)\n",
        "mse = score(val_targets, preds)\n",
        "print(\"Score on validation set:\", mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final evaluation (after tuning)\n",
        "final_preds = predictor.predict(test_data)\n",
        "final_score = score(test_targets, final_preds)\n",
        "print(\"Final test score:\", final_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = utils.check_cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'utils' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-c28a9b5ddef1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnormalization_factor_temporal_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnormalization_factor_temporal_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnormalization_factor_temporal_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train data shape : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'utils' is not defined"
          ]
        }
      ],
      "source": [
        "train_data_loader = utils.prep_data(train_data, train_targets, batch_size=32,normalization_factor_temporal_data=[100])\n",
        "val_data_loader = utils.prep_data(val_data, val_targets, batch_size=32,normalization_factor_temporal_data=[100])\n",
        "test_data_loader = utils.prep_data(test_data, test_targets, batch_size=32,normalization_factor_temporal_data=[100])\n",
        "\n",
        "print(\"train data shape : \", train_data_loader.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "#-------- new code : Sambit, 20/02/2020 ------------------------------#\n",
        "# create a MLP in pytorch : 3 hidden dense layers, 16, 16, 8\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LearningCurveMLP(nn.Module):\n",
        "    \"\"\"\n",
        "    Create the architecture\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size, dropout=0):\n",
        "        \"\"\"\n",
        "        Default constructor\n",
        "        \"\"\"\n",
        "\n",
        "        super(LearningCurveMLP, self).__init__()\n",
        "\n",
        "        self.L1_linear = nn.Linear(7, 16)  # dense layer, 7 inputs (same as number of input features), 16 outputs, so 16 hidden units\n",
        "        self.L2_linear = nn.Linear(16, 16)\n",
        "        self.L3_linear = nn.Linear(16, 8)\n",
        "        self.L4_linear = nn.Linear(8, 1)\n",
        "\n",
        "        self.drpout = dropout\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward propagation function\n",
        "        \"\"\"\n",
        "\n",
        "        out1 = F.Dropout(F.Sigmoid(self.L1_linear(x)), p=0.3)\n",
        "        out2 = F.Dropout(F.Sigmoid(self.L2_linear(out1)), p=0.3)\n",
        "        out3 = F.Dropout(F.Sigmoid(self.L3_linear(out2)), p=0.3)\n",
        "\n",
        "        out = F.Sigmoid(self.L4_linear(out3))\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "cOrgWvjIaU8n"
      },
      "outputs": [],
      "source": [
        "class UnivariatMultiStepLSTM(torch.nn.Module):\n",
        "    \"\"\"An univariate multi-step LSTM that predicts from a single input sequence the validation learning curve\"\"\"\n",
        "    \n",
        "    def __init__(self,input_size, hidden_size, output_size, \n",
        "                 num_layers=1, lstm_dropout=0, bidirectional=False,fc_dropout=0):\n",
        "        super(UnivariatMultiStepLSTM,self).__init__()\n",
        "        \n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm_dropout = lstm_dropout\n",
        "        self.bidirectional = bidirectional\n",
        "        self.fc_dropout = fc_dropout\n",
        "\n",
        "        self.relu = torch.nn.functional.relu\n",
        "        self.encode_fc1 = torch.nn.Linear(7,int(self.hidden_size/4))\n",
        "        self.encode_bn1 = torch.nn.BatchNorm1d(int(self.hidden_size/4))\n",
        "        self.encode_fc2 = torch.nn.Linear(int(self.hidden_size/4),self.hidden_size)\n",
        "        self.encode_bn2 = torch.nn.BatchNorm1d(self.hidden_size)\n",
        "\n",
        "        self.lstm = torch.nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers,\n",
        "                            dropout=lstm_dropout, bidirectional=bidirectional)\n",
        "        \n",
        "        self.fc = torch.nn.Linear(self.hidden_size*10*2 if self.bidirectional else hidden_size*10,output_size)\n",
        "\n",
        "    def encode(self,x):\n",
        "        x = self.relu(self.encode_bn1(self.encode_fc1(x)))\n",
        "        return self.encode_bn2(self.encode_fc2(x))\n",
        "\n",
        "    def forward(self,x):\n",
        "        seq, config = x\n",
        "        batch_size = seq.size(0)\n",
        "\n",
        "        h0 = self.encode(config)\n",
        "        h0 = torch.stack([h0 for _ in range(self.num_layers*2 if self.bidirectional else self.num_layers)])\n",
        "        c0 = torch.zeros(self.num_layers*2 if self.bidirectional else self.num_layers, config.size()[0], self.hidden_size)\n",
        "        seq = torch.transpose(seq,1,0)\n",
        "        seq = seq.unsqueeze(-1)\n",
        "\n",
        "        lstm_out, _ = self.lstm(seq,(h0,c0))\n",
        "        lstm_out = lstm_out.permute(1,0,2)\n",
        "        lstm_out = lstm_out.contiguous().view(batch_size,-1)\n",
        "      \n",
        "        forecast = self.fc(lstm_out)\n",
        "        return forecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "sqyIN3cLHlwC"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, criterion, clip=5):\n",
        "    model.train()\n",
        "    epoch_loss = []\n",
        "    for val_acc, configs, targets in train_data_loader:\n",
        "      optimizer.zero_grad()\n",
        "      output = model([val_acc,configs])\n",
        "      loss = criterion(output, targets)\n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(),clip)\n",
        "      optimizer.step()\n",
        "      epoch_loss.append(loss.item())\n",
        "    return np.array(epoch_loss).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Lom0qSLfHh-J"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, criterion):\n",
        "  model.eval()\n",
        "  epoch_loss = []\n",
        "  with torch.no_grad():\n",
        "    for val_acc, configs, targets in val_data_loader:\n",
        "      output = model([val_acc, configs])\n",
        "      loss = criterion(output, targets)\n",
        "      epoch_loss.append(loss.item())\n",
        "  return np.array(epoch_loss).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9OFaN6Rx1Njn"
      },
      "outputs": [],
      "source": [
        "def test(model, criterion):\n",
        "    #model.load_state_dict(torch.load('content/models/model.pt'))\n",
        "    model.eval()\n",
        "    epoch_loss=[]\n",
        "    with torch.no_grad():\n",
        "      for val_acc, configs, targets in test_data_loader:\n",
        "        output = model([val_acc, configs])\n",
        "        loss = criterion(output, targets)\n",
        "        epoch_loss.append(loss.item())\n",
        "        \n",
        "    return np.array(epoch_loss).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "HBuizjkSCrXk"
      },
      "outputs": [],
      "source": [
        "def max_error(model, criterion):\n",
        "    #model.load_state_dict(torch.load('content/models/model.pt'))\n",
        "    model.eval()\n",
        "    epoch_loss=[]\n",
        "    with torch.no_grad():\n",
        "      for val_acc, configs, targets in test_data_loader:\n",
        "        output = model([val_acc, configs])\n",
        "        loss = np.abs(output.detach().numpy()-targets.detach().numpy().reshape(-1,1))\n",
        "        epoch_loss += loss.tolist()\n",
        "        \n",
        "    return np.array(epoch_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Iqtn_wsjIJxm"
      },
      "outputs": [],
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "      torch.nn.init.uniform_(param.data, -0.08, 0.08)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "colab_type": "code",
        "id": "yUioFDjfIIer",
        "outputId": "058c6547-7e62-45d5-e041-dbb0be224236"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "41766\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "UnivariatMultiStepLSTM(\n",
              "  (encode_fc1): Linear(in_features=7, out_features=8, bias=True)\n",
              "  (encode_bn1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (encode_fc2): Linear(in_features=8, out_features=35, bias=True)\n",
              "  (encode_bn2): BatchNorm1d(35, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (lstm): LSTM(1, 35, num_layers=2, dropout=0.5, bidirectional=True)\n",
              "  (fc): Linear(in_features=700, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 11,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_size = 1\n",
        "outcome_dim = 1\n",
        "hidden_dim=35\n",
        "num_layers=2\n",
        "config_size = 7\n",
        "bidirectional = True\n",
        "lstm_dropout=0.5\n",
        "fc_dropout=0.0\n",
        "\n",
        "model = UnivariatMultiStepLSTM(input_size, hidden_dim, outcome_dim, num_layers,\n",
        "                      lstm_dropout=lstm_dropout,bidirectional=bidirectional,fc_dropout=fc_dropout)\n",
        "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
        "print(pytorch_total_params)\n",
        "model.apply(init_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jR-Zp7gmnXU_"
      },
      "outputs": [],
      "source": [
        "epochs=200\n",
        "lr=0.01\n",
        "weight_decay = 10e-3\n",
        "T_0 = int(epochs/4)\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rnjIfsKuwSs_"
      },
      "outputs": [],
      "source": [
        "from collections import namedtuple\n",
        "train_stats = namedtuple(\"Stats\",[\"train_loss\", \"val_loss\"])\n",
        "stats = train_stats(train_loss=np.zeros(epochs),\n",
        "                     val_loss=np.zeros(epochs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "e565yxk3H7mX",
        "outputId": "e40c643d-1c58-44cd-a862-eef9bcd02523"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([20])) that is different to the input size (torch.Size([20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss decreased (inf --> 69.324066).  Saving model ...\n",
            "Epoch: 0\t Train Loss: 1505.536\t Val. Loss: 69.324\n",
            "Val loss decreased (69.324066 --> 63.472178).  Saving model ...\n",
            "Epoch: 1\t Train Loss: 81.310\t Val. Loss: 63.472\n",
            "Epoch: 2\t Train Loss: 79.564\t Val. Loss: 91.739\n",
            "Val loss decreased (63.472178 --> 62.456640).  Saving model ...\n",
            "Epoch: 3\t Train Loss: 81.428\t Val. Loss: 62.457\n",
            "Val loss decreased (62.456640 --> 62.332173).  Saving model ...\n",
            "Epoch: 4\t Train Loss: 81.048\t Val. Loss: 62.332\n",
            "Val loss decreased (62.332173 --> 62.097000).  Saving model ...\n",
            "Epoch: 5\t Train Loss: 77.678\t Val. Loss: 62.097\n",
            "Epoch: 6\t Train Loss: 76.837\t Val. Loss: 63.627\n",
            "Epoch: 7\t Train Loss: 76.987\t Val. Loss: 62.134\n",
            "Epoch: 8\t Train Loss: 77.556\t Val. Loss: 65.918\n",
            "Epoch: 9\t Train Loss: 78.863\t Val. Loss: 88.224\n",
            "Epoch: 10\t Train Loss: 79.217\t Val. Loss: 65.825\n",
            "Epoch: 11\t Train Loss: 76.923\t Val. Loss: 62.479\n",
            "Epoch: 12\t Train Loss: 77.953\t Val. Loss: 63.078\n",
            "Epoch: 13\t Train Loss: 77.424\t Val. Loss: 63.318\n",
            "Epoch: 14\t Train Loss: 78.987\t Val. Loss: 88.739\n",
            "Epoch: 15\t Train Loss: 79.434\t Val. Loss: 76.572\n",
            "Epoch: 16\t Train Loss: 79.390\t Val. Loss: 62.191\n",
            "Epoch: 17\t Train Loss: 78.345\t Val. Loss: 67.388\n",
            "Epoch: 18\t Train Loss: 78.481\t Val. Loss: 62.237\n",
            "Epoch: 19\t Train Loss: 86.216\t Val. Loss: 62.195\n",
            "Epoch: 20\t Train Loss: 76.583\t Val. Loss: 68.881\n",
            "Epoch: 21\t Train Loss: 77.964\t Val. Loss: 66.382\n",
            "Epoch: 22\t Train Loss: 76.440\t Val. Loss: 62.633\n",
            "Epoch: 23\t Train Loss: 76.716\t Val. Loss: 62.226\n",
            "Epoch: 24\t Train Loss: 76.655\t Val. Loss: 64.679\n",
            "Epoch: 25\t Train Loss: 78.859\t Val. Loss: 86.903\n",
            "Epoch: 26\t Train Loss: 77.652\t Val. Loss: 66.703\n",
            "Epoch: 27\t Train Loss: 80.018\t Val. Loss: 77.853\n",
            "Epoch: 28\t Train Loss: 79.050\t Val. Loss: 89.220\n",
            "Epoch: 29\t Train Loss: 78.930\t Val. Loss: 80.188\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-9f472701dc09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-df6dd2bf00fd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m       \u001b[0mepoch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "best_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  train_loss = train(model, optimizer, criterion)\n",
        "  val_loss = evaluate(model, criterion)\n",
        "\n",
        "  if val_loss < best_val_loss:\n",
        "    torch.save(model.state_dict(),\"content/models/model_5.pt\")    \n",
        "    print('Val loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(best_val_loss,val_loss))\n",
        "    best_val_loss = val_loss\n",
        "\n",
        "  print(f'Epoch: {epoch}\\t Train Loss: {train_loss:.3f}\\t Val. Loss: {val_loss:.3f}')\n",
        "  stats.train_loss[epoch] = train_loss\n",
        "  stats.val_loss[epoch] = val_loss\n",
        "\n",
        "  scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "IYsehDzCx2Km"
      },
      "outputs": [],
      "source": [
        "np.save(\"content/train_stats_5.npy\",stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "5loOywuhHem-"
      },
      "outputs": [],
      "source": [
        "def RMSELoss(yhat,y):\n",
        "    return torch.sqrt(torch.mean((yhat-y)**2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9vKyR0Rq1JxW"
      },
      "outputs": [],
      "source": [
        "test_loss = test(model, criterion)\n",
        "print(test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3veSufNOAfJN"
      },
      "outputs": [],
      "source": [
        "model_list = []\n",
        "for i in range(5):\n",
        "  model = UnivariatMultiStepLSTM(input_size, hidden_dim, outcome_dim, num_layers,\n",
        "                      lstm_dropout=lstm_dropout,bidirectional=bidirectional,fc_dropout=fc_dropout)\n",
        "  model.load_state_dict(torch.load(\"content/model_\"+str(i+1)+\".pt\"))\n",
        "  model_list.append(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "colab_type": "code",
        "id": "0ENml8i-BpID",
        "outputId": "1cb8e00a-026a-496b-8165-8a482542b78b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([20])) that is different to the input size (torch.Size([20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63.266495275497434\n"
          ]
        }
      ],
      "source": [
        "test_losses = []\n",
        "for i in range(5):\n",
        "  test_losses.append(test(model_list[i],criterion))\n",
        "print(np.array(test_losses).mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "Dz44UzJkCMhG",
        "outputId": "454cdbae-7763-4f6b-ce99-5cd354b33bc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.652655375003815\n"
          ]
        }
      ],
      "source": [
        "test_losses = []\n",
        "for i in range(5):\n",
        "  test_losses.append(test(model_list[i],RMSELoss))\n",
        "print(np.array(test_losses).mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "F5q7TUrvDCrz"
      },
      "outputs": [],
      "source": [
        "tmp = max_error(model_list[0],RMSELoss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "Wym5y3h6C4pr",
        "outputId": "571fb084-8282-4024-cbc3-013713069238"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "53.93588714599609\n"
          ]
        }
      ],
      "source": [
        "max_errors = []\n",
        "for i in range(5):\n",
        "  max_errors.append(max_error(model_list[i],RMSELoss).max())\n",
        "print(np.array(max_errors).mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "lK2YtfIJHWf1",
        "outputId": "9636baf9-ca28-4e91-da7d-a3df2de29d59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(500, 1)\n"
          ]
        }
      ],
      "source": [
        "max_errors = []\n",
        "for i in range(5):\n",
        "  max_errors.append(max_error(model_list[i],RMSELoss))\n",
        "print(np.array(max_errors).mean(axis=0).shape)\n",
        "np.save(\"max_errors\",np.array(max_errors).mean(axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "PJ5fKFDuvW75"
      },
      "outputs": [],
      "source": [
        "def test_ensemble(model_list, criterion):\n",
        "    #model.load_state_dict(torch.load('content/models/model.pt'))\n",
        "    epoch_loss=[]\n",
        "    with torch.no_grad():\n",
        "      for val_acc, configs, targets in test_data_loader:\n",
        "        output = []\n",
        "        for model in model_list:\n",
        "          model.eval()\n",
        "          output.append(model([val_acc, configs]))\n",
        "        output = torch.stack(output)\n",
        "        output = torch.mean(output,dim=0)\n",
        "        loss = criterion(output, targets.unsqueeze(-1))\n",
        "        epoch_loss.append(loss.item())\n",
        "        \n",
        "    return np.array(epoch_loss).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "qY1OeI5jvrE1",
        "outputId": "cff7e6e8-82fc-4a97-8264-4016cb5207ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "62.36482071876526\n"
          ]
        }
      ],
      "source": [
        "test_losses=test_ensemble(model_list,criterion)\n",
        "print(test_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "DIEwvzjUwzee",
        "outputId": "f97be8ff-9267-4b2d-a2f2-dd900d7a420a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.596453607082367\n"
          ]
        }
      ],
      "source": [
        "test_losses=test_ensemble(model_list,RMSELoss)\n",
        "print(test_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "JZMc9hPvw5CE"
      },
      "outputs": [],
      "source": [
        "def max_error_ensemble(model_list, criterion):\n",
        "    epoch_loss=[]\n",
        "    with torch.no_grad():\n",
        "      for val_acc, configs, targets in test_data_loader:\n",
        "        output = []\n",
        "        for model in model_list:\n",
        "          model.eval()\n",
        "          output.append(model([val_acc, configs]))\n",
        "        output = torch.stack(output)\n",
        "        output = torch.mean(output,dim=0)\n",
        "        loss = np.abs(output.detach().numpy()-targets.detach().numpy().reshape(-1,1))\n",
        "        epoch_loss += loss.tolist()\n",
        "        \n",
        "    return np.array(epoch_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "YVPlCR9jxLko",
        "outputId": "6ec6fde0-45aa-4900-d5f6-bc403b4319b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "53.935890197753906\n"
          ]
        }
      ],
      "source": [
        "test_losses=max_error_ensemble(model_list,RMSELoss)\n",
        "print(test_losses.max())"
      ]
    }
  ]
}