{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "colab": {
      "name": "Conditional Multi-Step Univariate LSTM.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJd_VxDKN8pn",
        "colab_type": "text"
      },
      "source": [
        "# Task A: Creating a Performance Predictor\n",
        "\n",
        "In this task, you will use training data from 2000 configurations on a single OpenML dataset to train a performance predictor. The data will be splitted into train, test and validation set and we will only use the first 10 epochs of the learning curves for predicitons. You are provided with the full benchmark logs for Fashion-MNIST, that is learning curves, config parameters and gradient statistics, and you can use them freely.\n",
        "\n",
        "For questions, you can contact zimmerl@informatik.uni-freiburg.\n",
        "\n",
        "__Note: Please use the dataloading and splits you are provided with in this notebook.__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqPBWpd5N8pt",
        "colab_type": "text"
      },
      "source": [
        "## Specifications:\n",
        "\n",
        "* Data: fashion_mnist.json\n",
        "* Number of datasets: 1\n",
        "* Number of configurations: 2000\n",
        "* Number of epochs seed during prediction: 10\n",
        "* Available data: Learning curves, architecture parameters and hyperparameters, gradient statistics \n",
        "* Target: Final validation accuracy\n",
        "* Evaluation metric: MSE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eYlSG9BN8py",
        "colab_type": "text"
      },
      "source": [
        "## Importing and splitting data\n",
        "\n",
        "__Note__: There are 51 steps logged, 50 epochs plus the 0th epoch, prior to any weight updates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aT8tEKUJOqNy",
        "colab_type": "code",
        "outputId": "583bc09f-9d55-4489-b296-4ddeb8c395ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "!pip install wget\n",
        "!pip install zipfile36"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9681 sha256=487a3dea6bf585d9774bfc8003b95740f7228a45176f185d873f622e9f1b03cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Collecting zipfile36\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/8a/3b7da0b0bd87d1ef05b74207827c72d348b56a0d6d83242582be18a81e02/zipfile36-0.1.3-py3-none-any.whl\n",
            "Installing collected packages: zipfile36\n",
            "Successfully installed zipfile36-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GSY73FpOPdD",
        "colab_type": "code",
        "outputId": "4b559f8d-9218-4692-cdd5-cd9559e45eb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import wget\n",
        "import zipfile\n",
        "dir_path = 'content/'\n",
        "filename=wget.download('https://ndownloader.figshare.com/files/21001311')\n",
        "with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"\")\n",
        "!rm fashion_mnist.zip\n",
        "wget.download('https://raw.githubusercontent.com/automl/LCBench/master/api.py')\n",
        "wget.download('https://raw.githubusercontent.com/infomon/Extrapolation-of-Learning-Curves/master/utils.py')\n",
        "!mkdir content/models\n",
        "!mkdir models"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘content/models’: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ql1OqCfgN8p4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "%cd ..\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from content.api import Benchmark\n",
        "import content.utils as utils\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2sQv_05N8qJ",
        "colab_type": "code",
        "outputId": "818278ce-2290-4f97-c748-5d3cda5500a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "bench_dir = dir_path+\"fashion_mnist.json\"\n",
        "bench = Benchmark(bench_dir, cache=False)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Loading data...\n",
            "==> No cached data found or cache set to False.\n",
            "==> Reading json data...\n",
            "==> Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eq4DxuuN8qe",
        "colab_type": "code",
        "outputId": "fa841c12-217e-4752-dbcb-9403f0fd43c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Read data\n",
        "def cut_data(data, cut_position):\n",
        "    targets = []\n",
        "    for dp in data:\n",
        "        targets.append(dp[\"Train/val_accuracy\"][50])\n",
        "        for tag in dp:\n",
        "            if tag.startswith(\"Train/\"):\n",
        "                dp[tag] = dp[tag][0:cut_position]\n",
        "    return data, targets\n",
        "\n",
        "def read_data():\n",
        "    dataset_name = 'Fashion-MNIST'\n",
        "    n_configs = bench.get_number_of_configs(dataset_name)\n",
        "    \n",
        "    # Query API\n",
        "    data = []\n",
        "    for config_id in range(n_configs):\n",
        "        data_point = dict()\n",
        "        data_point[\"config\"] = bench.query(dataset_name=dataset_name, tag=\"config\", config_id=config_id)\n",
        "        for tag in bench.get_queriable_tags(dataset_name=dataset_name, config_id=config_id):\n",
        "            if tag.startswith(\"Train/\"):\n",
        "                data_point[tag] = bench.query(dataset_name=dataset_name, tag=tag, config_id=config_id)    \n",
        "        data.append(data_point)\n",
        "        \n",
        "    # Split: 50% train, 25% validation, 25% test (the data is already shuffled)\n",
        "    indices = np.arange(n_configs)\n",
        "    ind_train = indices[0:int(np.floor(0.5*n_configs))]\n",
        "    ind_val = indices[int(np.floor(0.5*n_configs)):int(np.floor(0.75*n_configs))]\n",
        "    ind_test = indices[int(np.floor(0.75*n_configs)):]\n",
        "\n",
        "    array_data = np.array(data)\n",
        "    train_data = array_data[ind_train]\n",
        "    val_data = array_data[ind_val]\n",
        "    test_data = array_data[ind_test]\n",
        "    \n",
        "    # Cut curves for validation and test\n",
        "    cut_position = 11\n",
        "    #val_data, val_targets = cut_data(val_data, cut_position)\n",
        "    #test_data, test_targets = cut_data(test_data, cut_position)\n",
        "    val_data, val_targets = cut_data(val_data, 51)\n",
        "    test_data, test_targets = cut_data(test_data, 51)\n",
        "    train_data, train_targets = cut_data(train_data, 51)   # Cut last value as it is repeated\n",
        "    \n",
        "    return train_data, val_data, test_data, train_targets, val_targets, test_targets\n",
        "    \n",
        "train_data, val_data, test_data, train_targets, val_targets, test_targets = read_data()\n",
        "\n",
        "print(\"Train:\", len(train_data))\n",
        "print(\"Validation:\", len(val_data))\n",
        "print(\"Test:\", len(test_data))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: 1000\n",
            "Validation: 500\n",
            "Test: 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PphdZ2aN8qv",
        "colab_type": "text"
      },
      "source": [
        "The data contains the configuration of the trained model and learning curves as well as global and layer-wise gradient statistics.\n",
        "\n",
        "__Note__: Not all parameters vary across different configurations. The varying parameters are batch_size, max_dropout, max_units, num_layers, learning_rate, momentum, weight_decay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ybnns3VKN8q0",
        "colab_type": "code",
        "outputId": "d5863a28-28dc-4775-aaae-6b21dae5c96d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# Config\n",
        "print(\"Config example:\", train_data[0][\"config\"])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Config example: {'batch_size': 71, 'imputation_strategy': 'mean', 'learning_rate_scheduler': 'cosine_annealing', 'loss': 'cross_entropy_weighted', 'network': 'shapedmlpnet', 'max_dropout': 0.025926231827891333, 'normalization_strategy': 'standardize', 'optimizer': 'sgd', 'cosine_annealing_T_max': 50, 'cosine_annealing_eta_min': 1e-08, 'activation': 'relu', 'max_units': 293, 'mlp_shape': 'funnel', 'num_layers': 3, 'learning_rate': 0.0018243300267253295, 'momentum': 0.21325193168301043, 'weight_decay': 0.020472816917443872}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua6h3ORrlA5N",
        "colab_type": "code",
        "outputId": "8e7dcfb9-f98f-4775-860b-c3abe30ddbc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "train_data[1][\"config\"]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'batch_size': 457,\n",
              " 'cosine_annealing_T_max': 50,\n",
              " 'cosine_annealing_eta_min': 1e-08,\n",
              " 'imputation_strategy': 'mean',\n",
              " 'learning_rate': 0.01239328605026128,\n",
              " 'learning_rate_scheduler': 'cosine_annealing',\n",
              " 'loss': 'cross_entropy_weighted',\n",
              " 'max_dropout': 0.5472322491757223,\n",
              " 'max_units': 950,\n",
              " 'mlp_shape': 'funnel',\n",
              " 'momentum': 0.16411425552061212,\n",
              " 'network': 'shapedmlpnet',\n",
              " 'normalization_strategy': 'standardize',\n",
              " 'num_layers': 4,\n",
              " 'optimizer': 'sgd',\n",
              " 'weight_decay': 0.09762768273307641}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTl67TOTN8rD",
        "colab_type": "code",
        "outputId": "bf386c0c-2eff-4c72-c42e-a3e3c2f04101",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "# Learning curve\n",
        "plt.plot(train_data[10][\"Train/val_accuracy\"])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f9cc5574240>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXGuPeBKN8rM",
        "colab_type": "code",
        "outputId": "27c26b4a-3dd3-4449-a9a1-3b78da9b8fa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "# Gradient statistics\n",
        "plt.plot(train_data[10][\"Train/layer_wise_gradient_mean_layer_0\"])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f9cc50bd6a0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAD4CAYAAAA6j0u4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7v8DbRIJDShuWn8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaYC_PH4N8rQ",
        "colab_type": "text"
      },
      "source": [
        "## A simple baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJrvEgLzN8rS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimpleLearningCurvePredictor():\n",
        "    \"\"\"A learning curve predictor that predicts the last observed epoch of the validation accuracy as final performance\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        pass\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        pass\n",
        "    \n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "        for datapoint in X:\n",
        "            predictions.append(datapoint[\"Train/val_accuracy\"][-1])\n",
        "        return predictions\n",
        "    \n",
        "def score(y_true, y_pred):\n",
        "    return mean_squared_error(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d23UZhgHN8rW",
        "colab_type": "code",
        "outputId": "50d70a5e-6594-493e-de6d-c70a6ee7594a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Training & tuning\n",
        "predictor = SimpleLearningCurvePredictor()\n",
        "predictor.fit(train_data, train_targets)\n",
        "preds = predictor.predict(val_data)\n",
        "mse = score(val_targets, preds)\n",
        "print(\"Score on validation set:\", mse)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score on validation set: 31.921338670622784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMWiY0XbN8rc",
        "colab_type": "code",
        "outputId": "a7d78f0c-47fb-4d55-e86a-9b3d23e4c76f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Final evaluation (after tuning)\n",
        "final_preds = predictor.predict(test_data)\n",
        "final_score = score(test_targets, final_preds)\n",
        "print(\"Final test score:\", final_score)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final test score: 24.199496266785523\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnEQJbbLyGG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_loader = utils.prep_data(train_data, train_targets, batch_size=32,normalization_factor_temporal_data=[100], one_shot=True)\n",
        "val_data_loader = utils.prep_data(val_data, val_targets, batch_size=32,normalization_factor_temporal_data=[100], one_shot=True)\n",
        "test_data_loader = utils.prep_data(test_data, test_targets, batch_size=32,normalization_factor_temporal_data=[100],one_shot=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBGim3i6CoCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderRNN(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, nof_configs, num_layers, dropout = 0.5, bidirectional=False):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        \n",
        "        self.nof_configs = nof_configs\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "        self.bidirectional = bidirectional\n",
        "        self.num_directions = 2 if bidirectional else 1\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = torch.nn.LSTM(input_size=input_size, \n",
        "                                  hidden_size=hidden_size,\n",
        "                                  num_layers=num_layers,\n",
        "                                  dropout=dropout,\n",
        "                                  bidirectional=bidirectional)\n",
        "\n",
        "        self.relu = torch.nn.functional.relu\n",
        "\n",
        "        self.encode_fc1 = torch.nn.Linear(self.nof_configs,int(self.hidden_size/2))\n",
        "        self.encode_bn1 = torch.nn.BatchNorm1d(int(self.hidden_size/2))\n",
        "        self.encode_fc2 = torch.nn.Linear(int(self.hidden_size/2),self.hidden_size)\n",
        "        self.encode_bn2 = torch.nn.BatchNorm1d(self.hidden_size)\n",
        "\n",
        "    def forward(self, seq, config):\n",
        "        h0 = self.initHidden(config)\n",
        "        c0 = self.initCell(seq.size()[0])\n",
        "        seq = torch.t(seq)\n",
        "        seq = seq.unsqueeze(-1)\n",
        "        output, (hidden,cell) = self.lstm(seq, (h0,c0))\n",
        "        return output, hidden, cell\n",
        "\n",
        "    def initHidden(self, config):\n",
        "        x = self.relu(self.encode_bn1(self.encode_fc1(config)))\n",
        "        x = self.relu(self.encode_bn2(self.encode_fc2(x)))\n",
        "        return torch.stack([x for _ in range(self.num_layers*self.num_directions)])\n",
        "\n",
        "    def initCell(self, batch_size):\n",
        "        return torch.zeros(self.num_layers*self.num_directions, batch_size, self.hidden_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dErX6on9FYyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderRNN(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers, dropout = 0.5, bidirectional=False):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        \n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "        self.bidirectional = bidirectional\n",
        "        self.num_directions = 2 if bidirectional else 1\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = torch.nn.LSTM(input_size=input_size, \n",
        "                                  hidden_size=hidden_size,\n",
        "                                  num_layers=num_layers,\n",
        "                                  dropout=dropout,\n",
        "                                  bidirectional=bidirectional)\n",
        "        \n",
        "        self.fc_out = torch.nn.Linear(hidden_size, output_size)\n",
        "        self.relu = torch.nn.functional.relu\n",
        "\n",
        "    def forward(self, seq, h0, c0):\n",
        "        seq = seq.unsqueeze(0)\n",
        "        seq = seq.unsqueeze(-1)\n",
        "        output, (hidden,cell) = self.lstm(seq, (h0,c0))\n",
        "        output = self.fc_out(output)\n",
        "        return output.squeeze(), hidden, cell\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hwbesz1Slf4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2Seq(torch.nn.Module):\n",
        "  def __init__(self, encoder, decoder):\n",
        "    super(Seq2Seq, self).__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "    assert encoder.hidden_size == decoder.hidden_size\n",
        "    assert encoder.num_layers == decoder.num_layers\n",
        "\n",
        "  def forward(self, source, target, teacher_forcing_ratio = 0.5):\n",
        "    batch_size = target.size()[0]\n",
        "    target_len = target.size()[1]\n",
        "\n",
        "    outputs = torch.zeros(target_len, batch_size, 1)\n",
        "\n",
        "    seq , config = source\n",
        "    output, hidden, cell = self.encoder(seq, config)\n",
        "\n",
        "    decoder_input = target[:,0]\n",
        "    for t in range(1, target_len):\n",
        "      output, hidden, cell = self.decoder(decoder_input, hidden, cell)\n",
        "      outputs[t] = output.unsqueeze(-1)\n",
        "      use_teacher_forcing = np.random.random() < teacher_forcing_ratio\n",
        "      decoder_input = target[:,t] if use_teacher_forcing else output\n",
        "    return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVWyDKngncVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_weights(m):\n",
        "  for name, param in m.named_parameters():\n",
        "        torch.nn.init.uniform_(param.data, -0.08, 0.08)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR-Zp7gmnXU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size = 1\n",
        "outcome_dim = 1\n",
        "hidden_dim = 32\n",
        "num_layers = 2\n",
        "config_size = 7\n",
        "lr=0.01\n",
        "epochs=100\n",
        "\n",
        "encoder = EncoderRNN(input_size, hidden_dim, config_size, num_layers)\n",
        "decoder = DecoderRNN(input_size, hidden_dim, outcome_dim, num_layers)\n",
        "model = Seq2Seq(encoder, decoder)\n",
        "model.apply(init_weights)\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=10e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk5Jat93mO_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, criterion, clip=5):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for val_acc, configs, targets in train_data_loader:\n",
        "      optimizer.zero_grad()\n",
        "      output = model([val_acc,configs],targets)\n",
        "      output = output.squeeze()\n",
        "      output = torch.t(output)\n",
        "      loss = criterion(output, targets)\n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(),clip)\n",
        "      optimizer.step()\n",
        "      epoch_loss += loss.item()\n",
        "    return epoch_loss/len(train_data_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GulE-3SosoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, criterion):\n",
        "  model.eval()\n",
        "  epoch_loss = 0\n",
        "  with torch.no_grad():\n",
        "    for val_acc, configs, targets in val_data_loader:\n",
        "      output = model([val_acc, configs], targets, 0)\n",
        "      output = output.squeeze()\n",
        "      output = torch.t(output)\n",
        "      loss = criterion(output, targets)\n",
        "      epoch_loss += loss.item()\n",
        "  return epoch_loss / len(val_data_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqBLkuRznl9y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "024380f7-b8b2-4d7b-abee-8522febb6971"
      },
      "source": [
        "best_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  train_loss = train(model, optimizer, criterion)\n",
        "  val_loss = evaluate(model, criterion)\n",
        "\n",
        "  if val_loss < best_val_loss:\n",
        "    torch.save(model.state_dict(),\"content/models/model.pt\")    \n",
        "    print('Val loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(best_val_loss,val_loss))\n",
        "    best_val_loss = val_loss\n",
        "\n",
        "  print(f'Epoch: {epoch}\\t Train Loss: {train_loss:.3f}\\t Val. Loss: {val_loss:.3f}')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Val loss decreased (inf --> 11.429819).  Saving model ...\n",
            "Epoch: 0\t Train Loss: 13.472\t Val. Loss: 11.430\n",
            "Epoch: 1\t Train Loss: 14.497\t Val. Loss: 11.471\n",
            "Epoch: 2\t Train Loss: 13.632\t Val. Loss: 16.561\n",
            "Epoch: 3\t Train Loss: 16.085\t Val. Loss: 11.483\n",
            "Epoch: 4\t Train Loss: 20.310\t Val. Loss: 18.983\n",
            "Epoch: 5\t Train Loss: 16.507\t Val. Loss: 14.132\n",
            "Epoch: 6\t Train Loss: 15.700\t Val. Loss: 25.996\n",
            "Epoch: 7\t Train Loss: 19.416\t Val. Loss: 13.997\n",
            "Epoch: 8\t Train Loss: 16.500\t Val. Loss: 17.395\n",
            "Epoch: 9\t Train Loss: 13.345\t Val. Loss: 16.767\n",
            "Epoch: 10\t Train Loss: 15.476\t Val. Loss: 12.779\n",
            "Epoch: 11\t Train Loss: 13.931\t Val. Loss: 13.053\n",
            "Epoch: 12\t Train Loss: 15.421\t Val. Loss: 12.090\n",
            "Epoch: 13\t Train Loss: 13.875\t Val. Loss: 12.831\n",
            "Epoch: 14\t Train Loss: 17.069\t Val. Loss: 12.656\n",
            "Epoch: 15\t Train Loss: 16.820\t Val. Loss: 13.463\n",
            "Epoch: 16\t Train Loss: 15.513\t Val. Loss: 13.287\n",
            "Epoch: 17\t Train Loss: 15.645\t Val. Loss: 15.562\n",
            "Epoch: 18\t Train Loss: 22.758\t Val. Loss: 20.379\n",
            "Epoch: 19\t Train Loss: 17.330\t Val. Loss: 18.142\n",
            "Epoch: 20\t Train Loss: 18.018\t Val. Loss: 18.568\n",
            "Epoch: 21\t Train Loss: 19.486\t Val. Loss: 12.054\n",
            "Epoch: 22\t Train Loss: 15.498\t Val. Loss: 14.021\n",
            "Val loss decreased (11.429819 --> 11.292218).  Saving model ...\n",
            "Epoch: 23\t Train Loss: 17.311\t Val. Loss: 11.292\n",
            "Epoch: 24\t Train Loss: 15.157\t Val. Loss: 15.357\n",
            "Epoch: 25\t Train Loss: 18.337\t Val. Loss: 16.612\n",
            "Epoch: 26\t Train Loss: 16.396\t Val. Loss: 13.799\n",
            "Epoch: 27\t Train Loss: 14.906\t Val. Loss: 15.761\n",
            "Epoch: 28\t Train Loss: 14.106\t Val. Loss: 13.428\n",
            "Epoch: 29\t Train Loss: 15.376\t Val. Loss: 15.001\n",
            "Epoch: 30\t Train Loss: 17.026\t Val. Loss: 12.176\n",
            "Epoch: 31\t Train Loss: 14.549\t Val. Loss: 14.803\n",
            "Epoch: 32\t Train Loss: 13.746\t Val. Loss: 14.120\n",
            "Epoch: 33\t Train Loss: 13.732\t Val. Loss: 11.386\n",
            "Epoch: 34\t Train Loss: 17.424\t Val. Loss: 14.427\n",
            "Epoch: 35\t Train Loss: 13.677\t Val. Loss: 11.440\n",
            "Val loss decreased (11.292218 --> 11.209404).  Saving model ...\n",
            "Epoch: 36\t Train Loss: 14.881\t Val. Loss: 11.209\n",
            "Epoch: 37\t Train Loss: 14.370\t Val. Loss: 13.578\n",
            "Epoch: 38\t Train Loss: 15.752\t Val. Loss: 14.601\n",
            "Epoch: 39\t Train Loss: 14.255\t Val. Loss: 11.386\n",
            "Epoch: 40\t Train Loss: 16.684\t Val. Loss: 11.539\n",
            "Val loss decreased (11.209404 --> 10.698310).  Saving model ...\n",
            "Epoch: 41\t Train Loss: 13.623\t Val. Loss: 10.698\n",
            "Epoch: 42\t Train Loss: 19.506\t Val. Loss: 14.588\n",
            "Epoch: 43\t Train Loss: 13.371\t Val. Loss: 12.490\n",
            "Epoch: 44\t Train Loss: 15.099\t Val. Loss: 13.254\n",
            "Epoch: 45\t Train Loss: 14.498\t Val. Loss: 15.655\n",
            "Epoch: 46\t Train Loss: 14.822\t Val. Loss: 12.090\n",
            "Epoch: 47\t Train Loss: 14.386\t Val. Loss: 13.671\n",
            "Epoch: 48\t Train Loss: 12.748\t Val. Loss: 11.746\n",
            "Epoch: 49\t Train Loss: 14.150\t Val. Loss: 13.384\n",
            "Epoch: 50\t Train Loss: 18.355\t Val. Loss: 13.426\n",
            "Epoch: 51\t Train Loss: 16.402\t Val. Loss: 13.674\n",
            "Epoch: 52\t Train Loss: 12.895\t Val. Loss: 12.787\n",
            "Epoch: 53\t Train Loss: 14.193\t Val. Loss: 13.355\n",
            "Epoch: 54\t Train Loss: 14.406\t Val. Loss: 14.035\n",
            "Epoch: 55\t Train Loss: 17.447\t Val. Loss: 14.680\n",
            "Epoch: 56\t Train Loss: 13.625\t Val. Loss: 12.660\n",
            "Epoch: 57\t Train Loss: 14.280\t Val. Loss: 12.896\n",
            "Epoch: 58\t Train Loss: 15.348\t Val. Loss: 15.530\n",
            "Epoch: 59\t Train Loss: 19.060\t Val. Loss: 14.640\n",
            "Epoch: 60\t Train Loss: 18.832\t Val. Loss: 25.595\n",
            "Epoch: 61\t Train Loss: 18.019\t Val. Loss: 11.844\n",
            "Epoch: 62\t Train Loss: 14.182\t Val. Loss: 13.417\n",
            "Epoch: 63\t Train Loss: 13.587\t Val. Loss: 12.013\n",
            "Epoch: 64\t Train Loss: 16.073\t Val. Loss: 12.126\n",
            "Epoch: 65\t Train Loss: 13.077\t Val. Loss: 12.005\n",
            "Epoch: 66\t Train Loss: 15.091\t Val. Loss: 14.544\n",
            "Epoch: 67\t Train Loss: 16.369\t Val. Loss: 13.993\n",
            "Epoch: 68\t Train Loss: 14.020\t Val. Loss: 14.544\n",
            "Epoch: 69\t Train Loss: 14.462\t Val. Loss: 14.471\n",
            "Epoch: 70\t Train Loss: 13.492\t Val. Loss: 14.418\n",
            "Epoch: 71\t Train Loss: 13.596\t Val. Loss: 13.773\n",
            "Epoch: 72\t Train Loss: 14.800\t Val. Loss: 22.317\n",
            "Epoch: 73\t Train Loss: 16.448\t Val. Loss: 14.579\n",
            "Epoch: 74\t Train Loss: 12.739\t Val. Loss: 12.339\n",
            "Epoch: 75\t Train Loss: 14.552\t Val. Loss: 13.154\n",
            "Epoch: 76\t Train Loss: 12.613\t Val. Loss: 11.637\n",
            "Epoch: 77\t Train Loss: 17.222\t Val. Loss: 12.483\n",
            "Epoch: 78\t Train Loss: 12.938\t Val. Loss: 19.090\n",
            "Epoch: 79\t Train Loss: 16.002\t Val. Loss: 15.888\n",
            "Epoch: 80\t Train Loss: 15.657\t Val. Loss: 14.649\n",
            "Epoch: 81\t Train Loss: 17.274\t Val. Loss: 12.115\n",
            "Epoch: 82\t Train Loss: 17.456\t Val. Loss: 14.587\n",
            "Epoch: 83\t Train Loss: 13.786\t Val. Loss: 13.789\n",
            "Epoch: 84\t Train Loss: 16.941\t Val. Loss: 13.899\n",
            "Epoch: 85\t Train Loss: 13.147\t Val. Loss: 14.339\n",
            "Epoch: 86\t Train Loss: 15.245\t Val. Loss: 15.060\n",
            "Epoch: 87\t Train Loss: 16.558\t Val. Loss: 14.512\n",
            "Epoch: 88\t Train Loss: 21.027\t Val. Loss: 20.562\n",
            "Epoch: 89\t Train Loss: 18.743\t Val. Loss: 16.089\n",
            "Epoch: 90\t Train Loss: 16.150\t Val. Loss: 13.897\n",
            "Epoch: 91\t Train Loss: 14.734\t Val. Loss: 15.598\n",
            "Epoch: 92\t Train Loss: 16.566\t Val. Loss: 14.976\n",
            "Epoch: 93\t Train Loss: 17.831\t Val. Loss: 14.060\n",
            "Epoch: 94\t Train Loss: 14.912\t Val. Loss: 13.527\n",
            "Epoch: 95\t Train Loss: 15.294\t Val. Loss: 16.104\n",
            "Epoch: 96\t Train Loss: 14.000\t Val. Loss: 12.461\n",
            "Epoch: 97\t Train Loss: 18.468\t Val. Loss: 17.927\n",
            "Epoch: 98\t Train Loss: 16.650\t Val. Loss: 10.867\n",
            "Epoch: 99\t Train Loss: 17.609\t Val. Loss: 13.353\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OFaN6Rx1Njn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, criterion):\n",
        "    model.load_state_dict(torch.load('content/models/model.pt'))\n",
        "    model.eval()\n",
        "    test_losses = []\n",
        "    with torch.no_grad():\n",
        "      for val_acc, configs, targets in test_data_loader:\n",
        "        output = model([val_acc, configs], targets, 0)\n",
        "        output = output.squeeze()\n",
        "        output = torch.t(output)\n",
        "        loss = criterion(output[:,-1], targets[:,-1])\n",
        "        test_losses.append(loss.item())\n",
        "\n",
        "    print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "    return np.mean(test_losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vKyR0Rq1JxW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "29f3962f-dc99-4bb3-f2d0-6f4b91fbe154"
      },
      "source": [
        "test_acc = test(model, criterion)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 7.855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GTtrISY_Xru",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "e40a0b8e-edd4-4bb1-be80-05274be4697c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_curve(model):\n",
        "  model.load_state_dict(torch.load('content/models/model.pt'))\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      for val_acc, configs, targets in test_data_loader:\n",
        "        output = model([val_acc, configs], targets, 0)\n",
        "        output = output.squeeze()\n",
        "        output = torch.t(output)\n",
        "        plt.plot(np.arange(51),targets[31],c='g')\n",
        "        plt.plot(np.arange(51),output[31],c='r')\n",
        "        plt.show()\n",
        "        break\n",
        "\n",
        "plot_curve(model)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSgEuIhIoBbiISKAU4CIigVKAi4gE6v8DAjng4ExcukEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}